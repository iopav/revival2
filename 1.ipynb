{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args:\n",
      "Namespace(device='0,1,2,3', model_config='config/model_config_small.json', tokenizer_path='cache/vocab_small.txt', raw_data_path='data/train.json', tokenized_data_path='data/tokenized/', raw=True, epochs=5, batch_size=8, lr=0.00015, warmup_steps=2000, log_step=1, stride=768, gradient_accumulation=1, fp16=False, fp16_opt_level='O1', max_grad_norm=1.0, num_pieces=100, min_length=128, output_dir='model/', pretrained_model='', writer_dir='tensorboard_summary/', segment=False, bpe_token=False, encoder_json='tokenizations/encoder.json', vocab_bpe='tokenizations/vocab.bpe')\n",
      "config:\n",
      "{\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 10,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 13317\n",
      "}\n",
      "\n",
      "using device: cuda\n",
      "building files\n",
      "reading lines\n",
      "finish\n",
      "files built\n",
      "number of parameters: 81894144\n",
      "calculating total steps\n",
      "total steps = 3480\n",
      "starting training\n",
      "epoch 1\n",
      "time: 2024-09-28 22:46:41.588605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (4276545 > 999999). Running this sequence through the model will result in indexing errors\n",
      "\n",
      "100%|██████████| 100/100 [00:15<00:00,  6.63it/s]\n",
      "100%|██████████| 100/100 [00:15<00:00,  6.63it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 125.98it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 125.98it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\GPT2-Chinese\\train.py\", line 251, in <module>\n",
      "    main()\n",
      "  File \"f:\\GPT2-Chinese\\train.py\", line 191, in main\n",
      "    outputs = model.forward(input_ids=batch_inputs, labels=batch_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\transformers\\modeling_gpt2.py\", line 528, in forward\n",
      "    transformer_outputs = self.transformer(input_ids,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\transformers\\modeling_gpt2.py\", line 438, in forward\n",
      "    outputs = block(hidden_states,\n",
      "              ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\transformers\\modeling_gpt2.py\", line 228, in forward\n",
      "    output_attn = self.attn(self.ln_1(x),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\transformers\\modeling_gpt2.py\", line 192, in forward\n",
      "    attn_outputs = self._attn(query, key, value, attention_mask, head_mask)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\transformers\\modeling_gpt2.py\", line 144, in _attn\n",
      "    w = torch.matmul(q, k)\n",
      "        ^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 1.57 GiB is free. Of the allocated memory 5.30 GiB is allocated by PyTorch, and 42.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "! python train.py --raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args:\n",
      "Namespace(device='0,1,2,3', model_config='config/model_config_small.json', tokenizer_path='cache/vocab_small.txt', raw_data_path='data/train.json', tokenized_data_path='data/tokenized/', raw=True, epochs=5, batch_size=8, lr=0.00015, warmup_steps=2000, log_step=1, stride=768, gradient_accumulation=1, fp16=False, fp16_opt_level='O1', max_grad_norm=1.0, num_pieces=100, output_dir='model/', pretrained_model='', segment=False)\n",
      "config:\n",
      "{\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 10,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 13317\n",
      "}\n",
      "\n",
      "using device: cuda\n",
      "building files\n",
      "reading lines\n",
      "finish\n",
      "files built\n",
      "calculating total steps\n",
      "total steps = 3480\n",
      "starting training\n",
      "epoch 1\n",
      "time: 2024-09-28 22:52:12.512771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  1%|          | 1/100 [00:00<00:12,  8.16it/s]\n",
      "  2%|▏         | 2/100 [00:00<00:13,  7.14it/s]\n",
      "  3%|▎         | 3/100 [00:00<00:12,  7.64it/s]\n",
      "  4%|▍         | 4/100 [00:00<00:12,  7.96it/s]\n",
      "  5%|▌         | 5/100 [00:00<00:11,  8.13it/s]\n",
      "  6%|▌         | 6/100 [00:00<00:12,  7.60it/s]\n",
      "  7%|▋         | 7/100 [00:00<00:12,  7.61it/s]\n",
      "  8%|▊         | 8/100 [00:01<00:11,  7.86it/s]\n",
      "  9%|▉         | 9/100 [00:01<00:11,  7.94it/s]\n",
      " 10%|█         | 10/100 [00:01<00:11,  7.91it/s]\n",
      " 11%|█         | 11/100 [00:01<00:11,  7.74it/s]\n",
      " 12%|█▏        | 12/100 [00:01<00:11,  7.70it/s]\n",
      " 13%|█▎        | 13/100 [00:01<00:11,  7.90it/s]\n",
      " 14%|█▍        | 14/100 [00:01<00:10,  7.97it/s]\n",
      " 15%|█▌        | 15/100 [00:01<00:10,  7.85it/s]\n",
      " 16%|█▌        | 16/100 [00:02<00:10,  7.92it/s]\n",
      " 17%|█▋        | 17/100 [00:02<00:10,  8.03it/s]\n",
      " 18%|█▊        | 18/100 [00:02<00:10,  8.13it/s]\n",
      " 19%|█▉        | 19/100 [00:02<00:09,  8.13it/s]\n",
      " 20%|██        | 20/100 [00:02<00:09,  8.16it/s]\n",
      " 21%|██        | 21/100 [00:02<00:09,  8.10it/s]\n",
      " 22%|██▏       | 22/100 [00:02<00:09,  8.11it/s]\n",
      " 23%|██▎       | 23/100 [00:02<00:09,  8.19it/s]\n",
      " 24%|██▍       | 24/100 [00:03<00:09,  8.06it/s]\n",
      " 25%|██▌       | 25/100 [00:03<00:09,  8.14it/s]\n",
      " 26%|██▌       | 26/100 [00:03<00:09,  8.14it/s]\n",
      " 27%|██▋       | 27/100 [00:03<00:09,  8.01it/s]\n",
      " 28%|██▊       | 28/100 [00:03<00:08,  8.05it/s]\n",
      " 29%|██▉       | 29/100 [00:03<00:08,  8.14it/s]\n",
      " 30%|███       | 30/100 [00:03<00:08,  7.99it/s]\n",
      " 31%|███       | 31/100 [00:03<00:08,  8.06it/s]\n",
      " 32%|███▏      | 32/100 [00:04<00:08,  8.06it/s]\n",
      " 33%|███▎      | 33/100 [00:04<00:08,  7.76it/s]\n",
      " 34%|███▍      | 34/100 [00:04<00:08,  7.90it/s]\n",
      " 35%|███▌      | 35/100 [00:04<00:08,  7.97it/s]\n",
      " 36%|███▌      | 36/100 [00:04<00:07,  8.03it/s]\n",
      " 37%|███▋      | 37/100 [00:04<00:08,  7.84it/s]\n",
      " 38%|███▊      | 38/100 [00:04<00:08,  7.67it/s]\n",
      " 39%|███▉      | 39/100 [00:04<00:07,  7.81it/s]\n",
      " 40%|████      | 40/100 [00:05<00:07,  7.80it/s]\n",
      " 41%|████      | 41/100 [00:05<00:07,  7.93it/s]\n",
      " 42%|████▏     | 42/100 [00:05<00:07,  7.79it/s]\n",
      " 43%|████▎     | 43/100 [00:05<00:07,  7.72it/s]\n",
      " 44%|████▍     | 44/100 [00:05<00:07,  7.21it/s]\n",
      " 45%|████▌     | 45/100 [00:05<00:07,  7.49it/s]\n",
      " 46%|████▌     | 46/100 [00:05<00:07,  7.49it/s]\n",
      " 47%|████▋     | 47/100 [00:05<00:07,  7.45it/s]\n",
      " 48%|████▊     | 48/100 [00:06<00:06,  7.53it/s]\n",
      " 49%|████▉     | 49/100 [00:06<00:07,  7.17it/s]\n",
      " 50%|█████     | 50/100 [00:06<00:06,  7.49it/s]\n",
      " 51%|█████     | 51/100 [00:06<00:06,  7.46it/s]\n",
      " 52%|█████▏    | 52/100 [00:06<00:06,  7.62it/s]\n",
      " 53%|█████▎    | 53/100 [00:06<00:06,  7.65it/s]\n",
      " 54%|█████▍    | 54/100 [00:06<00:06,  7.45it/s]\n",
      " 55%|█████▌    | 55/100 [00:07<00:05,  7.66it/s]\n",
      " 56%|█████▌    | 56/100 [00:07<00:05,  7.86it/s]\n",
      " 57%|█████▋    | 57/100 [00:07<00:05,  7.85it/s]\n",
      " 58%|█████▊    | 58/100 [00:07<00:05,  7.98it/s]\n",
      " 59%|█████▉    | 59/100 [00:07<00:05,  7.93it/s]\n",
      " 60%|██████    | 60/100 [00:07<00:05,  7.71it/s]\n",
      " 61%|██████    | 61/100 [00:07<00:04,  7.82it/s]\n",
      " 62%|██████▏   | 62/100 [00:07<00:04,  7.95it/s]\n",
      " 63%|██████▎   | 63/100 [00:08<00:04,  7.97it/s]\n",
      " 64%|██████▍   | 64/100 [00:08<00:04,  8.07it/s]\n",
      " 65%|██████▌   | 65/100 [00:08<00:04,  7.84it/s]\n",
      " 66%|██████▌   | 66/100 [00:08<00:04,  7.03it/s]\n",
      " 67%|██████▋   | 67/100 [00:08<00:04,  7.08it/s]\n",
      " 68%|██████▊   | 68/100 [00:08<00:04,  6.59it/s]\n",
      " 69%|██████▉   | 69/100 [00:08<00:04,  6.39it/s]\n",
      " 70%|███████   | 70/100 [00:09<00:04,  6.26it/s]\n",
      " 71%|███████   | 71/100 [00:09<00:05,  5.69it/s]\n",
      " 72%|███████▏  | 72/100 [00:09<00:05,  5.16it/s]\n",
      " 73%|███████▎  | 73/100 [00:09<00:04,  5.65it/s]\n",
      " 74%|███████▍  | 74/100 [00:09<00:04,  6.06it/s]\n",
      " 75%|███████▌  | 75/100 [00:09<00:03,  6.30it/s]\n",
      " 76%|███████▌  | 76/100 [00:10<00:03,  6.67it/s]\n",
      " 77%|███████▋  | 77/100 [00:10<00:03,  7.00it/s]\n",
      " 78%|███████▊  | 78/100 [00:10<00:03,  7.26it/s]\n",
      " 79%|███████▉  | 79/100 [00:10<00:02,  7.48it/s]\n",
      " 80%|████████  | 80/100 [00:10<00:02,  7.66it/s]\n",
      " 81%|████████  | 81/100 [00:10<00:02,  7.77it/s]\n",
      " 82%|████████▏ | 82/100 [00:10<00:02,  7.82it/s]\n",
      " 83%|████████▎ | 83/100 [00:11<00:02,  7.83it/s]\n",
      " 84%|████████▍ | 84/100 [00:11<00:02,  7.65it/s]\n",
      " 85%|████████▌ | 85/100 [00:11<00:01,  7.59it/s]\n",
      " 86%|████████▌ | 86/100 [00:11<00:01,  7.69it/s]\n",
      " 87%|████████▋ | 87/100 [00:11<00:01,  7.60it/s]\n",
      " 88%|████████▊ | 88/100 [00:11<00:01,  6.69it/s]\n",
      " 89%|████████▉ | 89/100 [00:11<00:01,  6.84it/s]\n",
      " 90%|█████████ | 90/100 [00:11<00:01,  7.08it/s]\n",
      " 91%|█████████ | 91/100 [00:12<00:01,  7.28it/s]\n",
      " 92%|█████████▏| 92/100 [00:12<00:01,  7.40it/s]\n",
      " 93%|█████████▎| 93/100 [00:12<00:00,  7.39it/s]\n",
      " 94%|█████████▍| 94/100 [00:12<00:00,  7.32it/s]\n",
      " 95%|█████████▌| 95/100 [00:12<00:00,  7.52it/s]\n",
      " 96%|█████████▌| 96/100 [00:12<00:00,  7.72it/s]\n",
      " 97%|█████████▋| 97/100 [00:12<00:00,  7.88it/s]\n",
      " 98%|█████████▊| 98/100 [00:13<00:00,  7.98it/s]\n",
      " 99%|█████████▉| 99/100 [00:13<00:00,  7.92it/s]\n",
      "100%|██████████| 100/100 [00:13<00:00,  7.89it/s]\n",
      "100%|██████████| 100/100 [00:13<00:00,  7.53it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  5%|▌         | 5/100 [00:00<00:02, 46.10it/s]\n",
      " 11%|█         | 11/100 [00:00<00:01, 52.70it/s]\n",
      " 17%|█▋        | 17/100 [00:00<00:02, 39.06it/s]\n",
      " 22%|██▏       | 22/100 [00:00<00:02, 34.92it/s]\n",
      " 27%|██▋       | 27/100 [00:00<00:01, 38.75it/s]\n",
      " 33%|███▎      | 33/100 [00:00<00:01, 42.72it/s]\n",
      " 38%|███▊      | 38/100 [00:00<00:01, 42.99it/s]\n",
      " 43%|████▎     | 43/100 [00:01<00:01, 36.97it/s]\n",
      " 48%|████▊     | 48/100 [00:01<00:01, 31.38it/s]\n",
      " 53%|█████▎    | 53/100 [00:01<00:01, 34.21it/s]\n",
      " 57%|█████▋    | 57/100 [00:01<00:01, 34.81it/s]\n",
      " 62%|██████▏   | 62/100 [00:01<00:00, 38.35it/s]\n",
      " 67%|██████▋   | 67/100 [00:01<00:01, 24.93it/s]\n",
      " 71%|███████   | 71/100 [00:02<00:01, 27.54it/s]\n",
      " 77%|███████▋  | 77/100 [00:02<00:00, 32.88it/s]\n",
      " 82%|████████▏ | 82/100 [00:02<00:00, 36.62it/s]\n",
      " 87%|████████▋ | 87/100 [00:02<00:00, 34.79it/s]\n",
      " 91%|█████████ | 91/100 [00:02<00:00, 35.43it/s]\n",
      " 96%|█████████▌| 96/100 [00:02<00:00, 38.95it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 36.38it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\GPT2-Chinese\\train_single.py\", line 227, in <module>\n",
      "    main()\n",
      "  File \"f:\\GPT2-Chinese\\train_single.py\", line 169, in main\n",
      "    outputs = model.forward(input_ids=batch_inputs, labels=batch_labels)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\transformers\\modeling_gpt2.py\", line 528, in forward\n",
      "    transformer_outputs = self.transformer(input_ids,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\transformers\\modeling_gpt2.py\", line 438, in forward\n",
      "    outputs = block(hidden_states,\n",
      "              ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\transformers\\modeling_gpt2.py\", line 228, in forward\n",
      "    output_attn = self.attn(self.ln_1(x),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\transformers\\modeling_gpt2.py\", line 192, in forward\n",
      "    attn_outputs = self._attn(query, key, value, attention_mask, head_mask)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\gpt2\\Lib\\site-packages\\transformers\\modeling_gpt2.py\", line 146, in _attn\n",
      "    w = w / math.sqrt(v.size(-1))\n",
      "        ~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 1.20 GiB is free. Of the allocated memory 5.67 GiB is allocated by PyTorch, and 42.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "! python train_single.py --raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def clean_json(json_str):\n",
    "    # 移除无效的控制字符\n",
    "    json_str = re.sub(r'[\\x00-\\x1f\\x7f]', '', json_str)\n",
    "    return json_str\n",
    "\n",
    "with open('data/train.json', 'r', encoding='utf-8') as file:\n",
    "    json_str = file.read()\n",
    "    clean_str = clean_json(json_str)\n",
    "    data = json.loads(clean_str)\n",
    "    #保存\n",
    "    with open('data/train_clean.json', 'w', encoding='utf-8') as clean_file:\n",
    "        json.dump(data, clean_file, ensure_ascii=False, indent=4)\n",
    "file.close()\n",
    "clean_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python train_single.py --pretrained_model '/content/drive/MyDrive/GPT2-Chinese/model/heisai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python generate.py --length=150 --nsamples=4 \\\n",
    "  --prefix=\"德米安\" \\\n",
    "  --model_path=\"model/final_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu124\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
